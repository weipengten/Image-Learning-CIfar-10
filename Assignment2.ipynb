{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7d2b96",
   "metadata": {},
   "source": [
    "# Question 1:  Data Normalizaton (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50ee26e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.compat.v2' has no attribute '__internal__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-dc793218ad33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Data preprocessing and modeling related functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \"\"\"\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunctional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayout_map\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlayout_map_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbase_layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistribute_coordinator_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/backend_config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keras.backend.epsilon\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_dispatch_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \"\"\"Returns the value of the fuzz factor used in numeric expressions.\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.compat.v2' has no attribute '__internal__'"
     ]
    }
   ],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#Data preprocessing and modeling related functions\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "#Cross-validation and evaluation related functions\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "#Data preprocessing and modeling related functions\n",
    "# from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad6f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (50000, 32, 32, 3)\n",
      "Test set shape: (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Exploring the dataset\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "482ffe62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display images from dataset\n",
    "images = range(0,10)\n",
    "classes = list(np.unique(y_train))\n",
    "plt.figure(figsize=(20,10))\n",
    "for i in images:\n",
    "        plt.subplot(2,5,1 + i).set_title(classes[y_train[i][0]])\n",
    "        plt.imshow(x_train[i].reshape(32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bccf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (50000, 3072)\n",
      "Test set shape: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the arrays to have only 2 dimensions\n",
    "x_train = x_train.reshape(50000, 32 * 32 * 3)\n",
    "x_test  = x_test.reshape (10000, 32 * 32 * 3)\n",
    "\n",
    "print(\"Training set shape:\", x_train.shape)\n",
    "print(\"Test set shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da55d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting \"training\" dataset further into train,test datasets \n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c219c8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum and maximum values after min-max scaling are 0.0 and 1.0 respectively.\n",
      "The minimum and maximum values after min-max scaling and normalisation are -2.2122802734375 and 2.6272494792938232 respectively.\n",
      "[0.5128192  0.53400755 0.5202159  ... 0.49730805 0.4942249  0.449564  ]\n",
      "[0.2881187  0.28597057 0.31555888 ... 0.25485855 0.2457989  0.25905165]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection, preprocessing, metrics\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "## method (1) MinMax - is preferred when working with TensorFlow\n",
    "# minmax_scaler = preprocessing.MinMaxScaler()\n",
    "# x_train_ms= minmax_scaler.fit_transform(x_train)\n",
    "# x_valid_ms= minmax_scaler.fit_transform(x_valid)\n",
    "# x_test_ms= minmax_scaler.fit_transform(x_test)\n",
    "x_train_ms= x_train/255\n",
    "x_valid_ms= x_valid/255\n",
    "x_text_ms = x_test/255\n",
    "\n",
    "print(f\"The minimum and maximum values after min-max scaling are {np.min(x_train_ms)} and {np.max(x_train_ms)} respectively.\")\n",
    "\n",
    "## method (2) Standard Normalisation - after MinMax\n",
    "# standard_scaler = preprocessing.StandardScaler()\n",
    "# x_train_ss= standard_scaler.fit_transform(x_train)\n",
    "# x_valid_ss= standard_scaler.fit_transform(x_valid)\n",
    "# x_test_ss= standard_scaler.fit_transform(x_test)\n",
    "mean = np.mean(x_train_ms, axis=0)\n",
    "std = np.std(x_train_ms, axis=0)\n",
    "x_train_ss = (x_train_ms - mean) / std\n",
    "x_valid_ss = (x_valid_ms - mean )/ std\n",
    "x_test_ss = (x_text_ms - mean) / std\n",
    "\n",
    "print(f\"The minimum and maximum values after min-max scaling and normalisation are {np.min(x_train_ss)} and {np.max(x_train_ss)} respectively.\")\n",
    "    \n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14714a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By converting the target variables to one-hot format, we can ensure that they are compatible with \n",
    "# the output layer of the MLP model, which expects the target variables to be represented as a vector \n",
    "# of binary values. \n",
    "\n",
    "y_train_1hot = np_utils.to_categorical(y_train, 10)\n",
    "y_valid_1hot = np_utils.to_categorical(y_valid, 10) \n",
    "y_test_1hot  = np_utils.to_categorical(y_test , 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67b7b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create disctionary to keep track of accuracy of the models\n",
    "model_summary={}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec3f76",
   "metadata": {},
   "source": [
    "# Question 2:  Implementing a Multi-Layer Perceptron for CIFAR-10 Classification (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34499ba4",
   "metadata": {},
   "source": [
    "### (1.1) MLP with one hidden layer consisting of 128 neurons,adam \n",
    "    -Optimizer: Adam\n",
    "    -Loss: Cross Entropy\n",
    "    -Hidden Layers: 1\n",
    "    -Activation Layer: (ReLU, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05386ba4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8690 - accuracy: 0.3045\n",
      "Epoch 1: validation accuracy=0.304500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7664 - accuracy: 0.3570\n",
      "Epoch 2: validation accuracy=0.357000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6881 - accuracy: 0.3927\n",
      "Epoch 3: validation accuracy=0.392700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6417 - accuracy: 0.4036\n",
      "Epoch 4: validation accuracy=0.403600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5999 - accuracy: 0.4237\n",
      "Epoch 5: validation accuracy=0.423700\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5641 - accuracy: 0.4398\n",
      "Epoch 6: validation accuracy=0.439800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5574 - accuracy: 0.4422\n",
      "Epoch 7: validation accuracy=0.442200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5406 - accuracy: 0.4537\n",
      "Epoch 8: validation accuracy=0.453700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5468 - accuracy: 0.4478\n",
      "Epoch 9: validation accuracy=0.447800\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5268 - accuracy: 0.4560\n",
      "Epoch 10: validation accuracy=0.456000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5341 - accuracy: 0.4543\n",
      "Epoch 11: validation accuracy=0.454300\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 1.5364 - accuracy: 0.4603\n",
      "Epoch 12: validation accuracy=0.460300\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5214 - accuracy: 0.4618\n",
      "Epoch 13: validation accuracy=0.461800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4951 - accuracy: 0.4717\n",
      "Epoch 14: validation accuracy=0.471700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5087 - accuracy: 0.4684\n",
      "Epoch 15: validation accuracy=0.468400\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5088 - accuracy: 0.4675\n",
      "Epoch 16: validation accuracy=0.467500\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4957 - accuracy: 0.4738\n",
      "Epoch 17: validation accuracy=0.473800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5141 - accuracy: 0.4725\n",
      "Epoch 18: validation accuracy=0.472500\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5018 - accuracy: 0.4663\n",
      "Epoch 19: validation accuracy=0.466300\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5039 - accuracy: 0.4724\n",
      "Epoch 20: validation accuracy=0.472400\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5070 - accuracy: 0.4707\n",
      "Epoch 21: validation accuracy=0.470700\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4983 - accuracy: 0.4762\n",
      "Epoch 22: validation accuracy=0.476200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5510 - accuracy: 0.4598\n",
      "Epoch 23: validation accuracy=0.459800\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4913 - accuracy: 0.4766\n",
      "Epoch 24: validation accuracy=0.476600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5323 - accuracy: 0.4658\n",
      "Epoch 25: validation accuracy=0.465800\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5038 - accuracy: 0.4735\n",
      "Epoch 26: validation accuracy=0.473500\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5196 - accuracy: 0.4755\n",
      "Epoch 27: validation accuracy=0.475500\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5390 - accuracy: 0.4641\n",
      "Epoch 28: validation accuracy=0.464100\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5349 - accuracy: 0.4715\n",
      "Epoch 29: validation accuracy=0.471500\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1\n",
    "        print(\"patience =\",patience)\n",
    "        \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))\n",
    "\n",
    "model_summary[\"(1.1) MLP with one hidden layer consisting of 128 neurons,adam\"] = round(test_accuracy,2)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee546fe3",
   "metadata": {},
   "source": [
    "### (1.2) MLP with one hidden layer consisting of 128 neurons, sgd\n",
    "    -Optimizer: SGD\n",
    "    -Loss: Cross Entropy\n",
    "    -Hidden Layers: 1\n",
    "    -Activation Layer: (ReLU, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bba7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8372 - accuracy: 0.3487\n",
      "Epoch 1: validation accuracy=0.348700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7409 - accuracy: 0.3852\n",
      "Epoch 2: validation accuracy=0.385200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6918 - accuracy: 0.3940\n",
      "Epoch 3: validation accuracy=0.394000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6476 - accuracy: 0.4109\n",
      "Epoch 4: validation accuracy=0.410900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6185 - accuracy: 0.4203\n",
      "Epoch 5: validation accuracy=0.420300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5919 - accuracy: 0.4279\n",
      "Epoch 6: validation accuracy=0.427900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5761 - accuracy: 0.4357\n",
      "Epoch 7: validation accuracy=0.435700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5517 - accuracy: 0.4435\n",
      "Epoch 8: validation accuracy=0.443500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5430 - accuracy: 0.4482\n",
      "Epoch 9: validation accuracy=0.448200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5194 - accuracy: 0.4570\n",
      "Epoch 10: validation accuracy=0.457000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5104 - accuracy: 0.4584\n",
      "Epoch 11: validation accuracy=0.458400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4980 - accuracy: 0.4622\n",
      "Epoch 12: validation accuracy=0.462200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4841 - accuracy: 0.4705\n",
      "Epoch 13: validation accuracy=0.470500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4725 - accuracy: 0.4750\n",
      "Epoch 14: validation accuracy=0.475000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4658 - accuracy: 0.4763\n",
      "Epoch 15: validation accuracy=0.476300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4571 - accuracy: 0.4793\n",
      "Epoch 16: validation accuracy=0.479300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4470 - accuracy: 0.4850\n",
      "Epoch 17: validation accuracy=0.485000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4395 - accuracy: 0.4816\n",
      "Epoch 18: validation accuracy=0.481600\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4339 - accuracy: 0.4859\n",
      "Epoch 19: validation accuracy=0.485900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4453 - accuracy: 0.4845\n",
      "Epoch 20: validation accuracy=0.484500\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4203 - accuracy: 0.4906\n",
      "Epoch 21: validation accuracy=0.490600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4189 - accuracy: 0.4889\n",
      "Epoch 22: validation accuracy=0.488900\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4120 - accuracy: 0.4958\n",
      "Epoch 23: validation accuracy=0.495800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4064 - accuracy: 0.4973\n",
      "Epoch 24: validation accuracy=0.497300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3986 - accuracy: 0.4993\n",
      "Epoch 25: validation accuracy=0.499300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3960 - accuracy: 0.4992\n",
      "Epoch 26: validation accuracy=0.499200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4074 - accuracy: 0.4964\n",
      "Epoch 27: validation accuracy=0.496400\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3848 - accuracy: 0.5031\n",
      "Epoch 28: validation accuracy=0.503100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3993 - accuracy: 0.5002\n",
      "Epoch 29: validation accuracy=0.500200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3776 - accuracy: 0.5095\n",
      "Epoch 30: validation accuracy=0.509500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3837 - accuracy: 0.5105\n",
      "Epoch 31: validation accuracy=0.510500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3796 - accuracy: 0.5087\n",
      "Epoch 32: validation accuracy=0.508700\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3762 - accuracy: 0.5110\n",
      "Epoch 33: validation accuracy=0.511000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3623 - accuracy: 0.5185\n",
      "Epoch 34: validation accuracy=0.518500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3998 - accuracy: 0.5023\n",
      "Epoch 35: validation accuracy=0.502300\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3743 - accuracy: 0.5123\n",
      "Epoch 36: validation accuracy=0.512300\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3609 - accuracy: 0.5203\n",
      "Epoch 37: validation accuracy=0.520300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3742 - accuracy: 0.5129\n",
      "Epoch 38: validation accuracy=0.512900\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3816 - accuracy: 0.5142\n",
      "Epoch 39: validation accuracy=0.514200\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3834 - accuracy: 0.5166\n",
      "Epoch 40: validation accuracy=0.516600\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "        \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "        \n",
    "model_summary[\"(1.2) MLP with one hidden layer consisting of 128 neurons, sgd\"] = round(test_accuracy,2)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b61215",
   "metadata": {},
   "source": [
    "### (2.1) MLP with one hidden layer consisting of 256 neurons,adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abec6c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7817 - accuracy: 0.3457\n",
      "Epoch 1: validation accuracy=0.345700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7009 - accuracy: 0.3772\n",
      "Epoch 2: validation accuracy=0.377200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6356 - accuracy: 0.4107\n",
      "Epoch 3: validation accuracy=0.410700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5967 - accuracy: 0.4281\n",
      "Epoch 4: validation accuracy=0.428100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5988 - accuracy: 0.4313\n",
      "Epoch 5: validation accuracy=0.431300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5771 - accuracy: 0.4359\n",
      "Epoch 6: validation accuracy=0.435900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5518 - accuracy: 0.4484\n",
      "Epoch 7: validation accuracy=0.448400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5470 - accuracy: 0.4524\n",
      "Epoch 8: validation accuracy=0.452400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5632 - accuracy: 0.4490\n",
      "Epoch 9: validation accuracy=0.449000\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5195 - accuracy: 0.4577\n",
      "Epoch 10: validation accuracy=0.457700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5345 - accuracy: 0.4603\n",
      "Epoch 11: validation accuracy=0.460300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5243 - accuracy: 0.4634\n",
      "Epoch 12: validation accuracy=0.463400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5254 - accuracy: 0.4580\n",
      "Epoch 13: validation accuracy=0.458000\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5414 - accuracy: 0.4524\n",
      "Epoch 14: validation accuracy=0.452400\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5304 - accuracy: 0.4587\n",
      "Epoch 15: validation accuracy=0.458700\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5601 - accuracy: 0.4534\n",
      "Epoch 16: validation accuracy=0.453400\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5415 - accuracy: 0.4592\n",
      "Epoch 17: validation accuracy=0.459200\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "        \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "        \n",
    "model_summary[\"(2.1) MLP with one hidden layer consisting of 256 neurons,adam\"] = round(test_accuracy,2)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535f50f9",
   "metadata": {},
   "source": [
    "### (2.2) MLP with one hidden layer consisting of 256 neurons,sgd\n",
    "    -Optimizer: SGD\n",
    "    -Loss: Cross Entropy\n",
    "    -Hidden Layers: 1\n",
    "    -Activation Layer: (ReLU, softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee62f983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8210 - accuracy: 0.3520\n",
      "Epoch 1: validation accuracy=0.352000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7367 - accuracy: 0.3872\n",
      "Epoch 2: validation accuracy=0.387200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6831 - accuracy: 0.4067\n",
      "Epoch 3: validation accuracy=0.406700\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6465 - accuracy: 0.4160\n",
      "Epoch 4: validation accuracy=0.416000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6150 - accuracy: 0.4270\n",
      "Epoch 5: validation accuracy=0.427000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5925 - accuracy: 0.4337\n",
      "Epoch 6: validation accuracy=0.433700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5680 - accuracy: 0.4444\n",
      "Epoch 7: validation accuracy=0.444400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5484 - accuracy: 0.4500\n",
      "Epoch 8: validation accuracy=0.450000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5318 - accuracy: 0.4535\n",
      "Epoch 9: validation accuracy=0.453500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5168 - accuracy: 0.4576\n",
      "Epoch 10: validation accuracy=0.457600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4958 - accuracy: 0.4663\n",
      "Epoch 11: validation accuracy=0.466300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4896 - accuracy: 0.4694\n",
      "Epoch 12: validation accuracy=0.469400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4822 - accuracy: 0.4709\n",
      "Epoch 13: validation accuracy=0.470900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4752 - accuracy: 0.4733\n",
      "Epoch 14: validation accuracy=0.473300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4616 - accuracy: 0.4785\n",
      "Epoch 15: validation accuracy=0.478500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4475 - accuracy: 0.4825\n",
      "Epoch 16: validation accuracy=0.482500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4465 - accuracy: 0.4826\n",
      "Epoch 17: validation accuracy=0.482600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4450 - accuracy: 0.4822\n",
      "Epoch 18: validation accuracy=0.482200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4332 - accuracy: 0.4862\n",
      "Epoch 19: validation accuracy=0.486200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4246 - accuracy: 0.4892\n",
      "Epoch 20: validation accuracy=0.489200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4277 - accuracy: 0.4892\n",
      "Epoch 21: validation accuracy=0.489200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4159 - accuracy: 0.4927\n",
      "Epoch 22: validation accuracy=0.492700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4080 - accuracy: 0.4958\n",
      "Epoch 23: validation accuracy=0.495800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4102 - accuracy: 0.4951\n",
      "Epoch 24: validation accuracy=0.495100\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4000 - accuracy: 0.5016\n",
      "Epoch 25: validation accuracy=0.501600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3990 - accuracy: 0.4990\n",
      "Epoch 26: validation accuracy=0.499000\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3908 - accuracy: 0.5050\n",
      "Epoch 27: validation accuracy=0.505000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3778 - accuracy: 0.5075\n",
      "Epoch 28: validation accuracy=0.507500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3922 - accuracy: 0.5034\n",
      "Epoch 29: validation accuracy=0.503400\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3946 - accuracy: 0.4995\n",
      "Epoch 30: validation accuracy=0.499500\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3951 - accuracy: 0.5031\n",
      "Epoch 31: validation accuracy=0.503100\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3816 - accuracy: 0.5091\n",
      "Epoch 32: validation accuracy=0.509100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3791 - accuracy: 0.5129\n",
      "Epoch 33: validation accuracy=0.512900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3765 - accuracy: 0.5091\n",
      "Epoch 34: validation accuracy=0.509100\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3793 - accuracy: 0.5129\n",
      "Epoch 35: validation accuracy=0.512900\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3663 - accuracy: 0.5168\n",
      "Epoch 36: validation accuracy=0.516800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3825 - accuracy: 0.5111\n",
      "Epoch 37: validation accuracy=0.511100\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3717 - accuracy: 0.5171\n",
      "Epoch 38: validation accuracy=0.517100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3859 - accuracy: 0.5113\n",
      "Epoch 39: validation accuracy=0.511300\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3838 - accuracy: 0.5141\n",
      "Epoch 40: validation accuracy=0.514100\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
       " '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "        \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "\n",
    "model_summary[\"(2.2) MLP with one hidden layer consisting of 256 neurons,sgd\"] = round(test_accuracy,2)\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1049c054",
   "metadata": {},
   "source": [
    "### (3.1) MLP with two hidden layer consisting of 256 ,128 neurons, relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf33b186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8156 - accuracy: 0.3385\n",
      "Epoch 1: validation accuracy=0.338500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7413 - accuracy: 0.3677\n",
      "Epoch 2: validation accuracy=0.367700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6874 - accuracy: 0.3848\n",
      "Epoch 3: validation accuracy=0.384800\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6626 - accuracy: 0.3988\n",
      "Epoch 4: validation accuracy=0.398800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6354 - accuracy: 0.4075\n",
      "Epoch 5: validation accuracy=0.407500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5720 - accuracy: 0.4319\n",
      "Epoch 6: validation accuracy=0.431900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5710 - accuracy: 0.4328\n",
      "Epoch 7: validation accuracy=0.432800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5539 - accuracy: 0.4410\n",
      "Epoch 8: validation accuracy=0.441000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5588 - accuracy: 0.4346\n",
      "Epoch 9: validation accuracy=0.434600\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5361 - accuracy: 0.4393\n",
      "Epoch 10: validation accuracy=0.439300\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5133 - accuracy: 0.4572\n",
      "Epoch 11: validation accuracy=0.457200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5179 - accuracy: 0.4509\n",
      "Epoch 12: validation accuracy=0.450900\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5242 - accuracy: 0.4521\n",
      "Epoch 13: validation accuracy=0.452100\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5030 - accuracy: 0.4603\n",
      "Epoch 14: validation accuracy=0.460300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5356 - accuracy: 0.4552\n",
      "Epoch 15: validation accuracy=0.455200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5091 - accuracy: 0.4628\n",
      "Epoch 16: validation accuracy=0.462800\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5035 - accuracy: 0.4617\n",
      "Epoch 17: validation accuracy=0.461700\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4762 - accuracy: 0.4755\n",
      "Epoch 18: validation accuracy=0.475500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4921 - accuracy: 0.4752\n",
      "Epoch 19: validation accuracy=0.475200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4857 - accuracy: 0.4722\n",
      "Epoch 20: validation accuracy=0.472200\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.5111 - accuracy: 0.4647\n",
      "Epoch 21: validation accuracy=0.464700\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5384 - accuracy: 0.4653\n",
      "Epoch 22: validation accuracy=0.465300\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4935 - accuracy: 0.4735\n",
      "Epoch 23: validation accuracy=0.473500\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
       " '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53,\n",
       " '(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu': 0.48}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')  # Change activation function to softmax\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]  # Use y_train_1hot instead of y_train\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)  # Use y_valid_1hot instead of y_valid\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "            \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "\n",
    "model_summary[\"(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu\"]=round(test_accuracy,2)\n",
    "model_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec9bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "823cd73f",
   "metadata": {},
   "source": [
    "### Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83fdeec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9238 - accuracy: 0.2922\n",
      "Epoch 1: validation accuracy=0.292200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8747 - accuracy: 0.3093\n",
      "Epoch 2: validation accuracy=0.309300\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8406 - accuracy: 0.3334\n",
      "Epoch 3: validation accuracy=0.333400\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8168 - accuracy: 0.3419\n",
      "Epoch 4: validation accuracy=0.341900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8442 - accuracy: 0.3172\n",
      "Epoch 5: validation accuracy=0.317200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8159 - accuracy: 0.3368\n",
      "Epoch 6: validation accuracy=0.336800\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7685 - accuracy: 0.3566\n",
      "Epoch 7: validation accuracy=0.356600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7960 - accuracy: 0.3385\n",
      "Epoch 8: validation accuracy=0.338500\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7796 - accuracy: 0.3446\n",
      "Epoch 9: validation accuracy=0.344600\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8038 - accuracy: 0.3468\n",
      "Epoch 10: validation accuracy=0.346800\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7994 - accuracy: 0.3458\n",
      "Epoch 11: validation accuracy=0.345800\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7980 - accuracy: 0.3479\n",
      "Epoch 12: validation accuracy=0.347900\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
       " '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53,\n",
       " '(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu': 0.48,\n",
       " 'Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh': 0.36}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='tanh', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')  # Change activation function to softmax\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]  # Use y_train_1hot instead of y_train\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)  # Use y_valid_1hot instead of y_valid\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "            \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "\n",
    "        \n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "\n",
    "\n",
    "model_summary[\"Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh\"]=round(test_accuracy,2)\n",
    "model_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0d5df",
   "metadata": {},
   "source": [
    "### Testing 2: MLP with three hidden layer consisting of 256,128,64 neurons,tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12767c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 2.0142 - accuracy: 0.2404\n",
      "Epoch 1: validation accuracy=0.240400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9507 - accuracy: 0.2610\n",
      "Epoch 2: validation accuracy=0.261000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9248 - accuracy: 0.2789\n",
      "Epoch 3: validation accuracy=0.278900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9199 - accuracy: 0.2821\n",
      "Epoch 4: validation accuracy=0.282100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8942 - accuracy: 0.3005\n",
      "Epoch 5: validation accuracy=0.300500\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.9201 - accuracy: 0.2902\n",
      "Epoch 6: validation accuracy=0.290200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8839 - accuracy: 0.3098\n",
      "Epoch 7: validation accuracy=0.309800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8806 - accuracy: 0.3033\n",
      "Epoch 8: validation accuracy=0.303300\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8845 - accuracy: 0.3184\n",
      "Epoch 9: validation accuracy=0.318400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8784 - accuracy: 0.3032\n",
      "Epoch 10: validation accuracy=0.303200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8719 - accuracy: 0.3167\n",
      "Epoch 11: validation accuracy=0.316700\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.8827 - accuracy: 0.3117\n",
      "Epoch 12: validation accuracy=0.311700\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8796 - accuracy: 0.3064\n",
      "Epoch 13: validation accuracy=0.306400\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8732 - accuracy: 0.3125\n",
      "Epoch 14: validation accuracy=0.312500\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
       " '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53,\n",
       " '(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu': 0.48,\n",
       " 'Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh': 0.36,\n",
       " 'Testing 2: MLP with three hidden layer consisting of 256,128,64 neurons,tanh': 0.32}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='tanh', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(64, activation='tanh'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')  # Change activation function to softmax\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]  # Use y_train_1hot instead of y_train\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)  # Use y_valid_1hot instead of y_valid\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "            \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "\n",
    "\n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "\n",
    "\n",
    "model_summary[\"Testing 2: MLP with three hidden layer consisting of 256,128,64 neurons,tanh\"]=round(test_accuracy,2)\n",
    "model_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae13fe",
   "metadata": {},
   "source": [
    "### Testing 3:  MLP with three hidden layer consisting of 256,128,64 neurons,LeakyRelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b032cf75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.8372 - accuracy: 0.3287\n",
      "Epoch 1: validation accuracy=0.328700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7915 - accuracy: 0.3467\n",
      "Epoch 2: validation accuracy=0.346700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.7174 - accuracy: 0.3665\n",
      "Epoch 3: validation accuracy=0.366500\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6353 - accuracy: 0.4022\n",
      "Epoch 4: validation accuracy=0.402200\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.6249 - accuracy: 0.4226\n",
      "Epoch 5: validation accuracy=0.422600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5976 - accuracy: 0.4227\n",
      "Epoch 6: validation accuracy=0.422700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5814 - accuracy: 0.4359\n",
      "Epoch 7: validation accuracy=0.435900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5632 - accuracy: 0.4366\n",
      "Epoch 8: validation accuracy=0.436600\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5380 - accuracy: 0.4440\n",
      "Epoch 9: validation accuracy=0.444000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5295 - accuracy: 0.4470\n",
      "Epoch 10: validation accuracy=0.447000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4996 - accuracy: 0.4611\n",
      "Epoch 11: validation accuracy=0.461100\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5058 - accuracy: 0.4627\n",
      "Epoch 12: validation accuracy=0.462700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5076 - accuracy: 0.4556\n",
      "Epoch 13: validation accuracy=0.455600\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.5095 - accuracy: 0.4559\n",
      "Epoch 14: validation accuracy=0.455900\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4981 - accuracy: 0.4680\n",
      "Epoch 15: validation accuracy=0.468000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4946 - accuracy: 0.4673\n",
      "Epoch 16: validation accuracy=0.467300\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4767 - accuracy: 0.4737\n",
      "Epoch 17: validation accuracy=0.473700\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4849 - accuracy: 0.4744\n",
      "Epoch 18: validation accuracy=0.474400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4530 - accuracy: 0.4810\n",
      "Epoch 19: validation accuracy=0.481000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4396 - accuracy: 0.4920\n",
      "Epoch 20: validation accuracy=0.492000\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4225 - accuracy: 0.4938\n",
      "Epoch 21: validation accuracy=0.493800\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4404 - accuracy: 0.4878\n",
      "Epoch 22: validation accuracy=0.487800\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4043 - accuracy: 0.4927\n",
      "Epoch 23: validation accuracy=0.492700\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4400 - accuracy: 0.4805\n",
      "Epoch 24: validation accuracy=0.480500\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4269 - accuracy: 0.4984\n",
      "Epoch 25: validation accuracy=0.498400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4192 - accuracy: 0.4994\n",
      "Epoch 26: validation accuracy=0.499400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4055 - accuracy: 0.5049\n",
      "Epoch 27: validation accuracy=0.504900\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4484 - accuracy: 0.4951\n",
      "Epoch 28: validation accuracy=0.495100\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3980 - accuracy: 0.5122\n",
      "Epoch 29: validation accuracy=0.512200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3999 - accuracy: 0.5090\n",
      "Epoch 30: validation accuracy=0.509000\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.3999 - accuracy: 0.5133\n",
      "Epoch 31: validation accuracy=0.513300\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4555 - accuracy: 0.5002\n",
      "Epoch 32: validation accuracy=0.500200\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 1.3809 - accuracy: 0.5184\n",
      "Epoch 33: validation accuracy=0.518400\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4097 - accuracy: 0.5068\n",
      "Epoch 34: validation accuracy=0.506800\n",
      "patience = 1\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4006 - accuracy: 0.5074\n",
      "Epoch 35: validation accuracy=0.507400\n",
      "patience = 2\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4263 - accuracy: 0.5048\n",
      "Epoch 36: validation accuracy=0.504800\n",
      "patience = 3\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4175 - accuracy: 0.5139\n",
      "Epoch 37: validation accuracy=0.513900\n",
      "patience = 4\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4539 - accuracy: 0.5110\n",
      "Epoch 38: validation accuracy=0.511000\n",
      "patience = 5\n",
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
       " '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
       " '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
       " '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53,\n",
       " '(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu': 0.48,\n",
       " 'Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh': 0.36,\n",
       " 'Testing 2: MLP with three hidden layer consisting of 256,128,64 neurons,tanh': 0.32,\n",
       " 'Testing 3: MLP with three hidden layer consisting of 256,128,64 neurons,LeakyRelu': 0.5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Define the model architecture\n",
    "model = keras.Sequential([\n",
    "    # Input Layer\n",
    "    keras.layers.Dense(512, activation='leaky_relu', input_shape=(32*32*3,)),\n",
    "    \n",
    "    # Hidden Layers\n",
    "    keras.layers.Dense(256, activation='leaky_relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(128, activation='leaky_relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    keras.layers.Dense(64, activation='leaky_relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    \n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')  # Change activation function to softmax\n",
    "])\n",
    "\n",
    "# Compile the model with Adam optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using mini-batch learning\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "patience = 5\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, len(x_train_ms), batch_size):\n",
    "        batch_x, batch_y = x_train_ms[i:i+batch_size], y_train_1hot[i:i+batch_size]  # Use y_train_1hot instead of y_train\n",
    "        model.train_on_batch(batch_x, batch_y)\n",
    "    \n",
    "    # Evaluate the model on the validation set after each epoch\n",
    "    val_loss, val_acc = model.evaluate(x_valid_ms, y_valid_1hot)  # Use y_valid_1hot instead of y_valid\n",
    "    print('Epoch %d: validation accuracy=%f' % (epoch+1, val_acc))\n",
    "    \n",
    "    # Check if the validation accuracy has improved\n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        patience = 0\n",
    "    else:\n",
    "        patience += 1 \n",
    "        print(\"patience =\",patience)\n",
    "            \n",
    "    # Stop training if the validation accuracy does not improve after a certain number of epochs\n",
    "    if patience == 5:\n",
    "        break\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "# Evaluate final model on test set\n",
    "test_pred = model.predict(x_text_ms)\n",
    "test_accuracy = accuracy_score(np.argmax(y_test_1hot, axis=1), np.argmax(test_pred, axis=1))    \n",
    "\n",
    "model_summary[\"Testing 3: MLP with three hidden layer consisting of 256,128,64 neurons,LeakyRelu\"]=round(test_accuracy,2)\n",
    "model_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639662b",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a767776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test  = np_utils.to_categorical(y_test , 10)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "x_train  /= 255\n",
    "x_test   /= 255\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "transform_train = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        rotation_range = 10,\n",
    "        zoom_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        vertical_flip=True,\n",
    "        horizontal_flip=True)   # flip images horizontally\n",
    "\n",
    "validation_train = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_set = transform_train.flow(x_train[:40000], y_train[:40000], batch_size=32)\n",
    "validation_set = validation_train.flow(x_train[40000:], y_train[40000:], batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5745823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !nbmerge Assignment2.ipynb.ipynb file_2.ipynb file_3.ipynb > merged_ouput.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88bbc2f",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f443e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T14:47:18.151496Z",
     "iopub.status.busy": "2024-03-15T14:47:18.150816Z",
     "iopub.status.idle": "2024-03-15T14:47:23.010452Z",
     "shell.execute_reply": "2024-03-15T14:47:23.009307Z",
     "shell.execute_reply.started": "2024-03-15T14:47:18.151462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "\u001b[1m170498071/170498071\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "# Preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test , 10)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "x_train  /= 255\n",
    "x_test   /= 255\n",
    "\n",
    "\n",
    "transform_train = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        rotation_range = 10,\n",
    "#         zoom_range=0.1,\n",
    "#         shear_range=0.1,\n",
    "#         vertical_flip=True,\n",
    "        horizontal_flip=True)   # flip images horizontally\n",
    "\n",
    "validation_train = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_set = transform_train.flow(x_train[:40000], y_train[:40000], batch_size=32)\n",
    "validation_set = validation_train.flow(x_train[40000:], y_train[40000:], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167536b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9be054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0de142f",
   "metadata": {},
   "source": [
    "### [Question 3] Building a Convolutional Neural Network for CIFAR-10!\n",
    "\n",
    "- Batch Size: 64\n",
    "- Epochs: 50\n",
    "- Padding: Same\n",
    "- Kernel: 3*3\n",
    "- (Convolution-BatchNormalisation-Relu-MaxPooling) x 2 \n",
    "- Loss Function: Categorical Crossentropy\n",
    "- Dropout: 0.25,0.25,0.5\n",
    "\n",
    "\n",
    "###### `Padding: Same:` This means that the output spatial dimensions will be the same as the input spatial dimensions after applying the convolution operation. This is achieved by adding zeros around the borders of the input tensor so that the output spatial dimensions match the input spatial dimensions.\n",
    "###### `Kernel: 3x3:` A kernel size of 3x3 is a standard choice for convolutional neural networks because it provides a good balance between capturing local patterns and not overfitting to the training data. Larger kernel sizes can capture more complex patterns but may lead to overfitting, while smaller kernel sizes may not capture enough information.\n",
    "###### `(Convolution-BatchNormalisation-Relu-MaxPooling) x 2`: This sequence of layers is commonly used in convolutional neural networks because it allows the model to learn increasingly complex features while reducing overfitting.\n",
    "###### `Batch normalization` normalize the activations to improve generalization\n",
    "###### `ReLU activation functions` introduce non-linearity to the model\n",
    "###### `Max pooling` layers downsample the spatial dimensions to reduce computational complexity and help the model learn spatial hierarchies.\n",
    "###### `Loss Function: Categorical Crossentropy:` This loss function is commonly used for multi-class classification problems like image classification. It measures the difference between the predicted probabilities and the true labels by calculating the negative log likelihood of the true class. This encourages the model to output high probabilities for the correct classes and low probabilities for the incorrect classe\n",
    "###### `Dropout` is a regularization technique that helps prevent overfitting by randomly setting some of the neurons to zero during training. By using a high dropout rate (0.25) and (0.5), it is likely to reduce overfitting and contribute to better performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4e39b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T07:04:04.638532Z",
     "iopub.status.busy": "2024-03-15T07:04:04.637883Z",
     "iopub.status.idle": "2024-03-15T07:29:11.449641Z",
     "shell.execute_reply": "2024-03-15T07:29:11.448600Z",
     "shell.execute_reply.started": "2024-03-15T07:04:04.638502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - accuracy: 0.3316 - loss: 1.9646 - val_accuracy: 0.5006 - val_loss: 1.4243\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.5072 - loss: 1.3822 - val_accuracy: 0.4684 - val_loss: 1.5537\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.5543 - loss: 1.2376 - val_accuracy: 0.6303 - val_loss: 1.0467\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.5847 - loss: 1.1615 - val_accuracy: 0.6687 - val_loss: 0.9481\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6136 - loss: 1.0898 - val_accuracy: 0.6705 - val_loss: 0.9473\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6289 - loss: 1.0544 - val_accuracy: 0.6607 - val_loss: 0.9691\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6370 - loss: 1.0241 - val_accuracy: 0.5878 - val_loss: 1.2684\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6450 - loss: 1.0023 - val_accuracy: 0.7094 - val_loss: 0.8473\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6494 - loss: 0.9943 - val_accuracy: 0.6682 - val_loss: 0.9504\n",
      "Epoch 10/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6645 - loss: 0.9614 - val_accuracy: 0.6974 - val_loss: 0.8759\n",
      "Epoch 11/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 24ms/step - accuracy: 0.6671 - loss: 0.9484 - val_accuracy: 0.7249 - val_loss: 0.7998\n",
      "Epoch 12/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.6709 - loss: 0.9396 - val_accuracy: 0.7023 - val_loss: 0.8634\n",
      "Epoch 13/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6769 - loss: 0.9288 - val_accuracy: 0.7485 - val_loss: 0.7285\n",
      "Epoch 14/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6806 - loss: 0.9184 - val_accuracy: 0.6695 - val_loss: 0.9654\n",
      "Epoch 15/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.6877 - loss: 0.8970 - val_accuracy: 0.7519 - val_loss: 0.7136\n",
      "Epoch 16/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6861 - loss: 0.8930 - val_accuracy: 0.6636 - val_loss: 0.9898\n",
      "Epoch 17/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.6869 - loss: 0.8935 - val_accuracy: 0.6951 - val_loss: 0.8805\n",
      "Epoch 18/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6949 - loss: 0.8811 - val_accuracy: 0.6901 - val_loss: 0.9024\n",
      "Epoch 19/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.6987 - loss: 0.8684 - val_accuracy: 0.7546 - val_loss: 0.7045\n",
      "Epoch 20/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.6981 - loss: 0.8634 - val_accuracy: 0.7258 - val_loss: 0.8400\n",
      "Epoch 21/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7012 - loss: 0.8632 - val_accuracy: 0.6830 - val_loss: 0.9290\n",
      "Epoch 22/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.6965 - loss: 0.8648 - val_accuracy: 0.7571 - val_loss: 0.7020\n",
      "Epoch 23/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7038 - loss: 0.8403 - val_accuracy: 0.7422 - val_loss: 0.7484\n",
      "Epoch 24/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7074 - loss: 0.8337 - val_accuracy: 0.6996 - val_loss: 0.8738\n",
      "Epoch 25/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7060 - loss: 0.8467 - val_accuracy: 0.7406 - val_loss: 0.7369\n",
      "Epoch 26/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 23ms/step - accuracy: 0.7054 - loss: 0.8393 - val_accuracy: 0.7289 - val_loss: 0.7903\n",
      "Epoch 27/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7114 - loss: 0.8272 - val_accuracy: 0.7158 - val_loss: 0.8189\n",
      "Epoch 28/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 23ms/step - accuracy: 0.7076 - loss: 0.8333 - val_accuracy: 0.7423 - val_loss: 0.7583\n",
      "Epoch 29/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7107 - loss: 0.8205 - val_accuracy: 0.7321 - val_loss: 0.7736\n",
      "Epoch 30/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7098 - loss: 0.8257 - val_accuracy: 0.7567 - val_loss: 0.6952\n",
      "Epoch 31/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7148 - loss: 0.8201 - val_accuracy: 0.7703 - val_loss: 0.6569\n",
      "Epoch 32/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7174 - loss: 0.8105 - val_accuracy: 0.7426 - val_loss: 0.7515\n",
      "Epoch 33/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7151 - loss: 0.8184 - val_accuracy: 0.7492 - val_loss: 0.7233\n",
      "Epoch 34/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7183 - loss: 0.8158 - val_accuracy: 0.7618 - val_loss: 0.6913\n",
      "Epoch 35/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7217 - loss: 0.8014 - val_accuracy: 0.7539 - val_loss: 0.7095\n",
      "Epoch 36/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7175 - loss: 0.8138 - val_accuracy: 0.7182 - val_loss: 0.8192\n",
      "Epoch 37/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7168 - loss: 0.8115 - val_accuracy: 0.7394 - val_loss: 0.7418\n",
      "Epoch 38/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7228 - loss: 0.8049 - val_accuracy: 0.7540 - val_loss: 0.7226\n",
      "Epoch 39/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7231 - loss: 0.7979 - val_accuracy: 0.7532 - val_loss: 0.7162\n",
      "Epoch 40/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7223 - loss: 0.8009 - val_accuracy: 0.7304 - val_loss: 0.7989\n",
      "Epoch 41/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7261 - loss: 0.7920 - val_accuracy: 0.7243 - val_loss: 0.8213\n",
      "Epoch 42/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 23ms/step - accuracy: 0.7248 - loss: 0.7870 - val_accuracy: 0.7136 - val_loss: 0.8315\n",
      "Epoch 43/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 23ms/step - accuracy: 0.7257 - loss: 0.7920 - val_accuracy: 0.7575 - val_loss: 0.7154\n",
      "Epoch 44/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7317 - loss: 0.7818 - val_accuracy: 0.7591 - val_loss: 0.6927\n",
      "Epoch 45/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7278 - loss: 0.7846 - val_accuracy: 0.7561 - val_loss: 0.7035\n",
      "Epoch 46/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7317 - loss: 0.7732 - val_accuracy: 0.7415 - val_loss: 0.7651\n",
      "Epoch 47/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7279 - loss: 0.7790 - val_accuracy: 0.7758 - val_loss: 0.6491\n",
      "Epoch 48/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7333 - loss: 0.7740 - val_accuracy: 0.7438 - val_loss: 0.7459\n",
      "Epoch 49/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 23ms/step - accuracy: 0.7316 - loss: 0.7771 - val_accuracy: 0.7592 - val_loss: 0.6963\n",
      "Epoch 50/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 24ms/step - accuracy: 0.7268 - loss: 0.7833 - val_accuracy: 0.7635 - val_loss: 0.6958\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.7093\n",
      "Test loss: 0.7087291479110718\n",
      "Test acc: 0.7570000290870667\n"
     ]
    }
   ],
   "source": [
    "## CNN Archeticure\n",
    "def CNN():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]) )\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(32,(3, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    \n",
    "    \n",
    "# Train model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "\n",
    "cnn.fit(train_set, \n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        validation_data=validation_set, shuffle=True)\n",
    "\n",
    "loss, acc = cnn.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23644b6a",
   "metadata": {},
   "source": [
    "## [Question 4]  Leveraging a Pretrained Model for CIFAR-10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f57028",
   "metadata": {},
   "source": [
    "#### ResNet50 seems to be one of the better pretrained models, let's set it to take the shape of our input data of CIFAR-10 instead of the original settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f243696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T12:26:50.004396Z",
     "iopub.status.busy": "2024-03-15T12:26:50.003463Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 12:26:52.228937: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 12:26:52.229073: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 12:26:52.402768: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Load ResNet50 pretrained model\n",
    "# base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486a6ab",
   "metadata": {},
   "source": [
    "### 1st Attempt:  freezing the pretrained layers and only train the top layer and not resize to 224x224\n",
    "- Did not resize CIFAR to 224x224\n",
    "- unfreeze only top layer\n",
    "- Data Augmentation\n",
    "- dropout = 0.5\n",
    "- epoch =10\n",
    "- batch_size =32\n",
    "\n",
    "`Test acc: 0.337`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee88ffdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:43:19.818523Z",
     "iopub.status.busy": "2024-03-15T13:43:19.817745Z",
     "iopub.status.idle": "2024-03-15T13:49:53.817354Z",
     "shell.execute_reply": "2024-03-15T13:49:53.816418Z",
     "shell.execute_reply.started": "2024-03-15T13:43:19.818491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m   8/1250\u001b[0m \u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 27ms/step - accuracy: 0.1062 - loss: 3.0031"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710510215.475183     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1579 - loss: 2.3335"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710510253.492515     109 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 35ms/step - accuracy: 0.1580 - loss: 2.3334 - val_accuracy: 0.2845 - val_loss: 1.9758\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710510259.060521     112 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2443 - loss: 2.0692 - val_accuracy: 0.2813 - val_loss: 1.9792\n",
      "Epoch 3/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2604 - loss: 2.0226 - val_accuracy: 0.2896 - val_loss: 1.9479\n",
      "Epoch 4/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2721 - loss: 2.0023 - val_accuracy: 0.3214 - val_loss: 1.8842\n",
      "Epoch 5/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2743 - loss: 1.9952 - val_accuracy: 0.2921 - val_loss: 1.9096\n",
      "Epoch 6/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2760 - loss: 1.9980 - val_accuracy: 0.2960 - val_loss: 1.9264\n",
      "Epoch 7/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2798 - loss: 1.9764 - val_accuracy: 0.3306 - val_loss: 1.8778\n",
      "Epoch 8/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2807 - loss: 1.9833 - val_accuracy: 0.3118 - val_loss: 1.9270\n",
      "Epoch 9/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2792 - loss: 1.9783 - val_accuracy: 0.3108 - val_loss: 1.9069\n",
      "Epoch 10/10\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 29ms/step - accuracy: 0.2844 - loss: 1.9762 - val_accuracy: 0.3352 - val_loss: 1.8566\n",
      "\u001b[1m 16/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.3642 - loss: 1.8311"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710510589.553399     111 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 14ms/step - accuracy: 0.3421 - loss: 1.8449\n",
      "Test loss: 1.852772831916809\n",
      "Test acc: 0.33730000257492065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710510593.794515     112 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.applications.ResNet50(input_shape=(32, 32, 3),\n",
    "                    include_top=False)\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "model5_resnet50 = tf.keras.Sequential([\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(rate=0.5), # add dropout layer with rate 0.5\n",
    "            tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model5_resnet50.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model5_resnet50.fit(train_set, \n",
    "        epochs=10,\n",
    "        batch_size=32,\n",
    "        validation_data=validation_set, shuffle=True)\n",
    "\n",
    "loss, acc = model5_resnet50.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8075b",
   "metadata": {},
   "source": [
    "#### It's obvious that the model is not performing well...\n",
    "\n",
    "#### This is likely due to the fact that these pre-trained models have their weights trained on a different dataset (ImageNet) that might not be oprimal for our CIFAR-10.\n",
    "\n",
    "#### By training the entire model together, we allow all layers to adapt to the new dataset and learn features that are more relevant for the CIFAR-10 classification task. This can lead to better performance compared to only training the top layer with frozen pre-trained layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c36f27",
   "metadata": {},
   "source": [
    "### 2nd Attempt:  unfreeze all layers but still did not resize to 224x224\n",
    "- Did not resize CIFAR to 224x224\n",
    "- unfreeze all layers\n",
    "- Data Augmentation\n",
    "- batch normalisation\n",
    "- dropout = 0.3\n",
    "- epoch =100\n",
    "- batch_size =16\n",
    "\n",
    "`Test acc: 0.785`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c548ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T14:49:05.232966Z",
     "iopub.status.busy": "2024-03-15T14:49:05.232294Z",
     "iopub.status.idle": "2024-03-15T15:54:03.608495Z",
     "shell.execute_reply": "2024-03-15T15:54:03.607289Z",
     "shell.execute_reply.started": "2024-03-15T14:49:05.232931Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   2/1250\u001b[0m \u001b[37m\u001b[0m \u001b[1m1:10\u001b[0m 57ms/step - accuracy: 0.1719 - loss: 2.9569   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710514213.025986     126 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1710514213.125035     126 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3096 - loss: 2.2660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710514252.689426     127 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 36ms/step - accuracy: 0.3097 - loss: 2.2658 - val_accuracy: 0.4276 - val_loss: 2.4720\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710514258.348643     126 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4766 - loss: 1.7669 - val_accuracy: 0.4648 - val_loss: 12.6117\n",
      "Epoch 3/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4778 - loss: 1.7521 - val_accuracy: 0.2231 - val_loss: 19.8326\n",
      "Epoch 4/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4179 - loss: 1.8601 - val_accuracy: 0.3785 - val_loss: 8.1623\n",
      "Epoch 5/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4168 - loss: 1.8642 - val_accuracy: 0.1402 - val_loss: 515.6135\n",
      "Epoch 6/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.3671 - loss: 1.9530 - val_accuracy: 0.3568 - val_loss: 27.5150\n",
      "Epoch 7/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.3837 - loss: 1.9206 - val_accuracy: 0.2772 - val_loss: 2.1623\n",
      "Epoch 8/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4041 - loss: 1.8376 - val_accuracy: 0.1740 - val_loss: 11.6895\n",
      "Epoch 9/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.3947 - loss: 1.7922 - val_accuracy: 0.4131 - val_loss: 2.6709\n",
      "Epoch 10/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4552 - loss: 1.6382 - val_accuracy: 0.2784 - val_loss: 2.4402\n",
      "Epoch 11/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4737 - loss: 1.5819 - val_accuracy: 0.4919 - val_loss: 1.7207\n",
      "Epoch 12/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5290 - loss: 1.3741 - val_accuracy: 0.3698 - val_loss: 2.5894\n",
      "Epoch 13/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5036 - loss: 1.4596 - val_accuracy: 0.4283 - val_loss: 3.7249\n",
      "Epoch 14/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5079 - loss: 1.4492 - val_accuracy: 0.4927 - val_loss: 1.4642\n",
      "Epoch 15/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5574 - loss: 1.3203 - val_accuracy: 0.5833 - val_loss: 1.1884\n",
      "Epoch 16/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5664 - loss: 1.2878 - val_accuracy: 0.4656 - val_loss: 2.2043\n",
      "Epoch 17/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6006 - loss: 1.1555 - val_accuracy: 0.5905 - val_loss: 1.2410\n",
      "Epoch 18/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5583 - loss: 1.3104 - val_accuracy: 0.6441 - val_loss: 1.2809\n",
      "Epoch 19/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6034 - loss: 1.1572 - val_accuracy: 0.6069 - val_loss: 1.1804\n",
      "Epoch 20/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6373 - loss: 1.0606 - val_accuracy: 0.6111 - val_loss: 1.2284\n",
      "Epoch 21/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6520 - loss: 1.0140 - val_accuracy: 0.6399 - val_loss: 1.4987\n",
      "Epoch 22/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6723 - loss: 0.9531 - val_accuracy: 0.6398 - val_loss: 3.1871\n",
      "Epoch 23/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6842 - loss: 0.9140 - val_accuracy: 0.5390 - val_loss: 4.9521\n",
      "Epoch 24/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6837 - loss: 0.9286 - val_accuracy: 0.6176 - val_loss: 11.4689\n",
      "Epoch 25/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6981 - loss: 0.8794 - val_accuracy: 0.7143 - val_loss: 1.2955\n",
      "Epoch 26/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7030 - loss: 0.8773 - val_accuracy: 0.7257 - val_loss: 2.2305\n",
      "Epoch 27/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7299 - loss: 0.7923 - val_accuracy: 0.6600 - val_loss: 1.7983\n",
      "Epoch 28/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7318 - loss: 0.7705 - val_accuracy: 0.7152 - val_loss: 2.4521\n",
      "Epoch 29/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7458 - loss: 0.7372 - val_accuracy: 0.6110 - val_loss: 1.4320\n",
      "Epoch 30/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7238 - loss: 0.8075 - val_accuracy: 0.6965 - val_loss: 0.9132\n",
      "Epoch 31/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7388 - loss: 0.7565 - val_accuracy: 0.7424 - val_loss: 3.5793\n",
      "Epoch 32/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7681 - loss: 0.6698 - val_accuracy: 0.7191 - val_loss: 2.4732\n",
      "Epoch 33/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7600 - loss: 0.6981 - val_accuracy: 0.6936 - val_loss: 2.3893\n",
      "Epoch 34/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7494 - loss: 0.7346 - val_accuracy: 0.7445 - val_loss: 0.8022\n",
      "Epoch 35/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7828 - loss: 0.6347 - val_accuracy: 0.7347 - val_loss: 1.3099\n",
      "Epoch 36/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7769 - loss: 0.6479 - val_accuracy: 0.7517 - val_loss: 1.1888\n",
      "Epoch 37/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7894 - loss: 0.6080 - val_accuracy: 0.7426 - val_loss: 1.4749\n",
      "Epoch 38/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7987 - loss: 0.5913 - val_accuracy: 0.7245 - val_loss: 1.0314\n",
      "Epoch 39/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8021 - loss: 0.5735 - val_accuracy: 0.7505 - val_loss: 1.9570\n",
      "Epoch 40/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7964 - loss: 0.5976 - val_accuracy: 0.7678 - val_loss: 1.1094\n",
      "Epoch 41/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8112 - loss: 0.5451 - val_accuracy: 0.7805 - val_loss: 0.8034\n",
      "Epoch 42/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8180 - loss: 0.5206 - val_accuracy: 0.7876 - val_loss: 0.6624\n",
      "Epoch 43/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8059 - loss: 0.5703 - val_accuracy: 0.7276 - val_loss: 3.4200\n",
      "Epoch 44/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8258 - loss: 0.5081 - val_accuracy: 0.7895 - val_loss: 0.6472\n",
      "Epoch 45/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8250 - loss: 0.5122 - val_accuracy: 0.7464 - val_loss: 1.6459\n",
      "Epoch 46/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8355 - loss: 0.4861 - val_accuracy: 0.7534 - val_loss: 1.4809\n",
      "Epoch 47/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8353 - loss: 0.4757 - val_accuracy: 0.7669 - val_loss: 1.3654\n",
      "Epoch 48/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8375 - loss: 0.4688 - val_accuracy: 0.7835 - val_loss: 0.7760\n",
      "Epoch 49/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8322 - loss: 0.4877 - val_accuracy: 0.7834 - val_loss: 1.1819\n",
      "Epoch 50/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8454 - loss: 0.4470 - val_accuracy: 0.7321 - val_loss: 2.1026\n",
      "Epoch 51/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8434 - loss: 0.4507 - val_accuracy: 0.7765 - val_loss: 1.6684\n",
      "Epoch 52/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8466 - loss: 0.4410 - val_accuracy: 0.4905 - val_loss: 2.0946\n",
      "Epoch 53/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8411 - loss: 0.4597 - val_accuracy: 0.7653 - val_loss: 0.8119\n",
      "Epoch 54/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8571 - loss: 0.4144 - val_accuracy: 0.7425 - val_loss: 0.9894\n",
      "Epoch 55/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8580 - loss: 0.4025 - val_accuracy: 0.7755 - val_loss: 0.6889\n",
      "Epoch 56/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.8587 - loss: 0.3995 - val_accuracy: 0.7305 - val_loss: 0.9147\n",
      "Epoch 57/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8673 - loss: 0.3867 - val_accuracy: 0.7993 - val_loss: 0.6557\n",
      "Epoch 58/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8682 - loss: 0.3742 - val_accuracy: 0.7585 - val_loss: 0.8140\n",
      "Epoch 59/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8736 - loss: 0.3619 - val_accuracy: 0.7903 - val_loss: 0.8470\n",
      "Epoch 60/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8717 - loss: 0.3707 - val_accuracy: 0.7216 - val_loss: 1.2543\n",
      "Epoch 61/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8705 - loss: 0.3784 - val_accuracy: 0.5599 - val_loss: 2.2203\n",
      "Epoch 62/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8412 - loss: 0.4600 - val_accuracy: 0.8106 - val_loss: 1.4841\n",
      "Epoch 63/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8749 - loss: 0.3590 - val_accuracy: 0.7149 - val_loss: 1.1857\n",
      "Epoch 64/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8519 - loss: 0.4233 - val_accuracy: 0.7763 - val_loss: 6.8871\n",
      "Epoch 65/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.8756 - loss: 0.3539 - val_accuracy: 0.7336 - val_loss: 2.0587\n",
      "Epoch 66/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8864 - loss: 0.3277 - val_accuracy: 0.7879 - val_loss: 0.8094\n",
      "Epoch 67/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8906 - loss: 0.3126 - val_accuracy: 0.7771 - val_loss: 0.8989\n",
      "Epoch 68/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8895 - loss: 0.3216 - val_accuracy: 0.8104 - val_loss: 0.6055\n",
      "Epoch 69/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8897 - loss: 0.3177 - val_accuracy: 0.7910 - val_loss: 1.1903\n",
      "Epoch 70/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8916 - loss: 0.3142 - val_accuracy: 0.7861 - val_loss: 1.9399\n",
      "Epoch 71/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8905 - loss: 0.3088 - val_accuracy: 0.7968 - val_loss: 4.8257\n",
      "Epoch 72/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8917 - loss: 0.3151 - val_accuracy: 0.7945 - val_loss: 4.1477\n",
      "Epoch 73/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8855 - loss: 0.3291 - val_accuracy: 0.7631 - val_loss: 5.1452\n",
      "Epoch 74/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8905 - loss: 0.3147 - val_accuracy: 0.7941 - val_loss: 1.5708\n",
      "Epoch 75/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9010 - loss: 0.2838 - val_accuracy: 0.8037 - val_loss: 1.2387\n",
      "Epoch 76/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8940 - loss: 0.3082 - val_accuracy: 0.8115 - val_loss: 0.7097\n",
      "Epoch 77/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9012 - loss: 0.2836 - val_accuracy: 0.8098 - val_loss: 0.6899\n",
      "Epoch 78/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9037 - loss: 0.2697 - val_accuracy: 0.7753 - val_loss: 0.8145\n",
      "Epoch 79/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9094 - loss: 0.2587 - val_accuracy: 0.7553 - val_loss: 0.8863\n",
      "Epoch 80/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9085 - loss: 0.2671 - val_accuracy: 0.7841 - val_loss: 0.8082\n",
      "Epoch 81/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9082 - loss: 0.2651 - val_accuracy: 0.8100 - val_loss: 0.7935\n",
      "Epoch 82/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9112 - loss: 0.2534 - val_accuracy: 0.7849 - val_loss: 1.2153\n",
      "Epoch 83/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9127 - loss: 0.2540 - val_accuracy: 0.5454 - val_loss: 2.1056\n",
      "Epoch 84/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.8763 - loss: 0.3726 - val_accuracy: 0.8077 - val_loss: 1.7598\n",
      "Epoch 85/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9203 - loss: 0.2349 - val_accuracy: 0.8213 - val_loss: 1.1032\n",
      "Epoch 86/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9235 - loss: 0.2213 - val_accuracy: 0.7966 - val_loss: 1.7084\n",
      "Epoch 87/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9180 - loss: 0.2386 - val_accuracy: 0.7941 - val_loss: 1.0971\n",
      "Epoch 88/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9202 - loss: 0.2316 - val_accuracy: 0.7108 - val_loss: 2.4602\n",
      "Epoch 89/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.9210 - loss: 0.2324 - val_accuracy: 0.7805 - val_loss: 1.7689\n",
      "Epoch 90/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9235 - loss: 0.2160 - val_accuracy: 0.7858 - val_loss: 4.5272\n",
      "Epoch 91/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9247 - loss: 0.2173 - val_accuracy: 0.7558 - val_loss: 7.4358\n",
      "Epoch 92/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9269 - loss: 0.2160 - val_accuracy: 0.7487 - val_loss: 2.7835\n",
      "Epoch 93/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.9285 - loss: 0.2131 - val_accuracy: 0.7765 - val_loss: 4.7280\n",
      "Epoch 94/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.9303 - loss: 0.2029 - val_accuracy: 0.8020 - val_loss: 5.3007\n",
      "Epoch 95/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9317 - loss: 0.1985 - val_accuracy: 0.7711 - val_loss: 6.3461\n",
      "Epoch 96/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9281 - loss: 0.2041 - val_accuracy: 0.7581 - val_loss: 2.6510\n",
      "Epoch 97/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.9310 - loss: 0.1994 - val_accuracy: 0.8059 - val_loss: 2.5821\n",
      "Epoch 98/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9340 - loss: 0.1935 - val_accuracy: 0.7886 - val_loss: 5.7836\n",
      "Epoch 99/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9313 - loss: 0.1996 - val_accuracy: 0.7832 - val_loss: 6.0420\n",
      "Epoch 100/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.9342 - loss: 0.1903 - val_accuracy: 0.7902 - val_loss: 4.0367\n",
      "\u001b[1m 16/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8113 - loss: 2.6586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710518035.715236     125 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 14ms/step - accuracy: 0.7905 - loss: 3.8917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1710518040.034699     124 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.087766647338867\n",
      "Test acc: 0.7854999899864197\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = tf.keras.applications.ResNet50(input_shape=(32, 32, 3), include_top=False)\n",
    "# Set trainable to True to update all layers during training\n",
    "pretrained_model.trainable = True\n",
    "model6_resnet50 = tf.keras.Sequential([\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(rate=0.3), # add dropout layer with rate 0.3\n",
    "            tf.keras.layers.Dense(10, activation='softmax')])\n",
    "model6_resnet50.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "model6_resnet50.fit(train_set, \n",
    "        epochs=100,\n",
    "        batch_size=16,\n",
    "        validation_data=validation_set, shuffle=True)\n",
    "loss, acc = model6_resnet50.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39da335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental import Resizing\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Preprocessing\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test , 10)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "x_train  /= 255\n",
    "x_test   /= 255\n",
    "\n",
    "# Define the ResNet50 model with resizing layer\n",
    "pretrained_model = tf.keras.applications.ResNet50(input_shape=(224, 224, 3),\n",
    "                    include_top=False)\n",
    "\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "resizing_layer = Resizing(size=(224, 224))\n",
    "\n",
    "model5_resnet50 = tf.keras.Sequential([\n",
    "            resizing_layer,\n",
    "            pretrained_model,\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(rate=0.5), # add dropout layer with rate 0.5\n",
    "            tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model5_resnet50.compile(optimizer='adam',loss = 'categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Generate the training and validation sets\n",
    "batch_size = 32\n",
    "num_batches = x_train.shape[0] // batch_size\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = min((i + 1) * batch_size, x_train.shape[0])\n",
    "    x_train[start:end] = tf.image.resize(x_train[start:end], [224, 224])\n",
    "\n",
    "x_test = tf.image.resize(x_test, [224, 224])\n",
    "\n",
    "transform_train = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        rotation_range = 10,\n",
    "#         zoom_range=0.1,\n",
    "#         shear_range=0.1,\n",
    "#         vertical_flip=True,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255)\n",
    "\n",
    "validation_train = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = transform_train.flow(x_train[:40000], y_train[:40000], batch_size=batch_size)\n",
    "validation_set = validation_train.flow(x_train[40000:], y_train[40000:], batch_size=batch_size)\n",
    "\n",
    "model5_resnet50.fit(train_set, \n",
    "        epochs=10,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_set, shuffle=True)\n",
    "\n",
    "loss, acc = model5_resnet50.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a191fbd9",
   "metadata": {
    "id": "rEvxel18eX0B"
   },
   "source": [
    "### 3rd Attempt: resizing our CIFAR-10 to 224x224 and unfreeze all layers\n",
    "- Resize CIFAR to 224x224 !!!\n",
    "- unfreeze all layers\n",
    "- Data Augmentation\n",
    "- batch normalisation\n",
    "- GlobalAveragePooling2D\n",
    "- dropout = 0.4\n",
    "- epoch =50\n",
    "- batch_size =64\n",
    "- EarlyStopping\n",
    "- ModelCheckpoint\n",
    "\n",
    "`Test acc: 0.898`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880453db",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-18T08:46:38.487885Z",
     "iopub.status.busy": "2024-03-18T08:46:38.487173Z",
     "iopub.status.idle": "2024-03-18T08:46:38.495707Z",
     "shell.execute_reply": "2024-03-18T08:46:38.494621Z",
     "shell.execute_reply.started": "2024-03-18T08:46:38.487848Z"
    }
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, save_model,load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, LeakyReLU, ELU, Conv2D, MaxPooling2D, Input, GlobalAveragePooling2D, Resizing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Activation, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "#Data preprocessing and modeling related functions\n",
    "# from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "231f5c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T08:52:05.303926Z",
     "iopub.status.busy": "2024-03-18T08:52:05.303463Z",
     "iopub.status.idle": "2024-03-18T08:52:06.372676Z",
     "shell.execute_reply": "2024-03-18T08:52:06.371849Z",
     "shell.execute_reply.started": "2024-03-18T08:52:05.303893Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 dataset\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "\n",
    "# Preprocessing\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test  = to_categorical(y_test , 10)\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "x_train  /= 255\n",
    "x_test   /= 255\n",
    "\n",
    "\n",
    "transform_train = ImageDataGenerator(\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        rotation_range = 10,\n",
    "#         zoom_range=0.1,\n",
    "#         shear_range=0.1,\n",
    "#         vertical_flip=True,\n",
    "        horizontal_flip=True)   # flip images horizontally\n",
    "\n",
    "validation_train = ImageDataGenerator()\n",
    "\n",
    "\n",
    "train_set = transform_train.flow(x_train[:40000], y_train[:40000], batch_size=32)\n",
    "validation_set = validation_train.flow(x_train[40000:], y_train[40000:], batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b673c715",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T09:27:14.006834Z",
     "iopub.status.busy": "2024-03-18T09:27:14.005709Z",
     "iopub.status.idle": "2024-03-18T10:30:58.755922Z",
     "shell.execute_reply": "2024-03-18T10:30:58.754560Z",
     "shell.execute_reply.started": "2024-03-18T09:27:14.006782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1710754107.922981     123 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.4787 - loss: 1.5068\n",
      "Epoch 1: val_accuracy improved from -inf to 0.66380, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 163ms/step - accuracy: 0.4788 - loss: 1.5066 - val_accuracy: 0.6638 - val_loss: 1.0889\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7365 - loss: 0.7618\n",
      "Epoch 2: val_accuracy improved from 0.66380 to 0.73060, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 157ms/step - accuracy: 0.7365 - loss: 0.7618 - val_accuracy: 0.7306 - val_loss: 0.8598\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7860 - loss: 0.6311\n",
      "Epoch 3: val_accuracy did not improve from 0.73060\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.7860 - loss: 0.6311 - val_accuracy: 0.7298 - val_loss: 0.9026\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8136 - loss: 0.5402\n",
      "Epoch 4: val_accuracy did not improve from 0.73060\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.8136 - loss: 0.5402 - val_accuracy: 0.6827 - val_loss: 1.1415\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8329 - loss: 0.4946\n",
      "Epoch 5: val_accuracy improved from 0.73060 to 0.85130, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 158ms/step - accuracy: 0.8329 - loss: 0.4946 - val_accuracy: 0.8513 - val_loss: 0.4353\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8488 - loss: 0.4398\n",
      "Epoch 6: val_accuracy did not improve from 0.85130\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 157ms/step - accuracy: 0.8488 - loss: 0.4398 - val_accuracy: 0.8168 - val_loss: 0.5621\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8653 - loss: 0.3936\n",
      "Epoch 7: val_accuracy did not improve from 0.85130\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.8652 - loss: 0.3936 - val_accuracy: 0.8379 - val_loss: 0.4838\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8752 - loss: 0.3656\n",
      "Epoch 8: val_accuracy did not improve from 0.85130\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.8752 - loss: 0.3656 - val_accuracy: 0.8460 - val_loss: 0.4843\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8825 - loss: 0.3458\n",
      "Epoch 9: val_accuracy improved from 0.85130 to 0.85920, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 157ms/step - accuracy: 0.8825 - loss: 0.3458 - val_accuracy: 0.8592 - val_loss: 0.4520\n",
      "Epoch 10/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8914 - loss: 0.3146\n",
      "Epoch 10: val_accuracy improved from 0.85920 to 0.88390, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 157ms/step - accuracy: 0.8914 - loss: 0.3146 - val_accuracy: 0.8839 - val_loss: 0.3700\n",
      "Epoch 11/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.8934 - loss: 0.3077\n",
      "Epoch 11: val_accuracy did not improve from 0.88390\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.8934 - loss: 0.3077 - val_accuracy: 0.8578 - val_loss: 0.4877\n",
      "Epoch 12/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.9047 - loss: 0.2828\n",
      "Epoch 12: val_accuracy did not improve from 0.88390\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 157ms/step - accuracy: 0.9047 - loss: 0.2828 - val_accuracy: 0.8535 - val_loss: 0.4808\n",
      "Epoch 13/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.9103 - loss: 0.2629\n",
      "Epoch 13: val_accuracy did not improve from 0.88390\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 157ms/step - accuracy: 0.9103 - loss: 0.2629 - val_accuracy: 0.8718 - val_loss: 0.4328\n",
      "Epoch 14/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9140 - loss: 0.2513\n",
      "Epoch 14: val_accuracy improved from 0.88390 to 0.90310, saving model to best_model.h5.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 157ms/step - accuracy: 0.9140 - loss: 0.2513 - val_accuracy: 0.9031 - val_loss: 0.3052\n",
      "Epoch 15/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9194 - loss: 0.2282\n",
      "Epoch 15: val_accuracy did not improve from 0.90310\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.9194 - loss: 0.2282 - val_accuracy: 0.8660 - val_loss: 0.4572\n",
      "Epoch 16/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9245 - loss: 0.2229\n",
      "Epoch 16: val_accuracy did not improve from 0.90310\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 156ms/step - accuracy: 0.9245 - loss: 0.2229 - val_accuracy: 0.8748 - val_loss: 0.4272\n",
      "Epoch 17/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9302 - loss: 0.2041\n",
      "Epoch 17: val_accuracy did not improve from 0.90310\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.9302 - loss: 0.2041 - val_accuracy: 0.8755 - val_loss: 0.4376\n",
      "Epoch 18/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9306 - loss: 0.1992\n",
      "Epoch 18: val_accuracy did not improve from 0.90310\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.9306 - loss: 0.1993 - val_accuracy: 0.8708 - val_loss: 0.4339\n",
      "Epoch 19/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.9362 - loss: 0.1898\n",
      "Epoch 19: val_accuracy did not improve from 0.90310\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 156ms/step - accuracy: 0.9362 - loss: 0.1898 - val_accuracy: 0.9006 - val_loss: 0.3413\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 38\u001b[0m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(train_set, \n\u001b[1;32m     33\u001b[0m         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m     34\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[1;32m     35\u001b[0m         validation_data\u001b[38;5;241m=\u001b[39mvalidation_set, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, model_checkpoint])\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Evaluate final model on test set\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest acc:\u001b[39m\u001b[38;5;124m'\u001b[39m, acc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "pretrained_model = ResNet50(input_shape=(224, 224, 3),\n",
    "                    include_top=False)\n",
    "\n",
    "pretrained_model.trainable = True\n",
    "\n",
    "model = Sequential([\n",
    "          Resizing(224, 224),  # Resize images to 224x224\n",
    "            pretrained_model,\n",
    "            BatchNormalization(),\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1024, activation='relu'),\n",
    "            Dropout(0.4),\n",
    "            Dense(10, activation='softmax', dtype='float32'),\n",
    "        ])\n",
    "\n",
    "# Compile the model with the same optimizer and loss function\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping parameters\n",
    "early_stopping_patience = 5 # Stop training if no improvement after 5 epochs\n",
    "early_stopping_min_delta = 0.01 # Stop training if improvement is less than 0.01%\n",
    "\n",
    "# Create EarlyStopping callback object\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=early_stopping_patience, min_delta=early_stopping_min_delta)\n",
    "\n",
    "# Define where to save the best model based on validation accuracy\n",
    "best_model_path = 'best_model.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback object\n",
    "model_checkpoint = ModelCheckpoint(best_model_path + '.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "# Continue training from the last saved model\n",
    "model.fit(train_set, \n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        validation_data=validation_set, shuffle=True,callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "# Evaluate final model on test set\n",
    "loss, acc = best_model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43653c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-18T10:44:36.502629Z",
     "iopub.status.busy": "2024-03-18T10:44:36.502209Z",
     "iopub.status.idle": "2024-03-18T10:44:55.534181Z",
     "shell.execute_reply": "2024-03-18T10:44:55.533197Z",
     "shell.execute_reply.started": "2024-03-18T10:44:36.502599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.8978 - loss: 0.3459\n",
      "Test loss: 0.3532184064388275\n",
      "Test acc: 0.8982999920845032\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final model on test set\n",
    "loss, acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test acc:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca991f8",
   "metadata": {},
   "source": [
    "# Assignment Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea72b149",
   "metadata": {},
   "source": [
    "###### In Question 2: We experimented with several hidden layers, optimisers, combinations of neurons and arrived with our best model at \"(2.2) MLP with one hidden layer consisting of 256 neurons,sgd'\" with a test accuracy of 0.53. This demonstrates to us that more layers and neurons might not necessarily mean better performance as they might tend to overfit and lead to huge validation loss. This hints to us that experimentation plays a big part especially in deep learning. Dropouts were also used in our models.\n",
    "###### In Question 3: CNN performed much better than MLP , possibly it's designed to capture spatial hierarchies in images and are translation invariant. We experimented with both Pytorch and Tensorflow. We have given up on Pytorch due to being unfamiliar with it's complicated functionality and the lack of time, however it is believed that Pytorch is a much more professional approach to CNN. We started off with creating a transform function to declare the augmentations we wanted. Size requirements need to matching and were highly confusing in Pytorch (refer to convNet model in appendix below) but Tensorflow has less requirements and we only need to understand the input shape required. Reasons for our choice of parameters/hyperparameters are:\n",
    "####### `Padding: Same:` This means that the output spatial dimensions will be the same as the input spatial dimensions after applying the convolution operation. This is achieved by adding zeros around the borders of the input tensor so that the output spatial dimensions match the input spatial dimensions.\n",
    "####### `Kernel: 3x3:` A kernel size of 3x3 is a standard choice for convolutional neural networks because it provides a good balance between capturing local patterns and not overfitting to the training data. Larger kernel sizes can capture more complex patterns but may lead to overfitting, while smaller kernel sizes may not capture enough information.\n",
    "####### `(Convolution-BatchNormalisation-Relu-MaxPooling) x 2`: This sequence of layers is commonly used in convolutional neural networks because it allows the model to learn increasingly complex features while reducing overfitting.\n",
    "####### `Batch normalization` normalize the activations to improve generalization\n",
    "####### `ReLU activation functions` introduce non-linearity to the model. Although there are other activation functions like LeakyRelu and ELU that are said to reduce the \"Vanishing Gradient\" problem, Relu still proves to a highly effective activation that serves it purpose and there hasn't been clear evidence that other activation functions are necessarily better like what we have experimented for our MLP.\n",
    "####### `Max pooling` layers downsample the spatial dimensions to reduce computational complexity and help the model learn spatial hierarchies.\n",
    "####### `Loss Function: Categorical Crossentropy:` This loss function is commonly used for multi-class classification problems like image classification. It measures the difference between the predicted probabilities and the true labels by calculating the negative log likelihood of the true class. This encourages the model to output high probabilities for the correct classes and low probabilities for the incorrect classe\n",
    "####### `Dropout` is a regularization technique that helps prevent overfitting by randomly setting some of the neurons to zero during training. By using a high dropout rate (0.25) and (0.5), it is likely to reduce overfitting and contribute to better performance.\n",
    "###### In Question 4: ResNet50 is a powerful and efficient pre-trained model for image classification tasks, especially when computational resources are limited. However, we faced challenges when using it to classify the CIFAR-10 dataset due to differences in input size and optimal features for the task. To overcome these challenges, we applied techniques such as data augmentation and normalization during preprocessing, and retrained the entire model on our dataset. While we made mistakes in resizing the input data, we were able to achieve adequate accuracy with the correct preprocessing techniques. Firstly, we tried unfreezing only the top layer intially but it proved to be insufficient and achieved subpar performance of  *0.337* test acc. Secondly, we tried to unfreeze all layers and gotten a better performance of *0.785* for test acc. Thirdly, we realise we actually need to resize our images to the optimal 224x224 for Resnet50 which it was tailored for but we faced multiple crashes and ran out of our allocated memory in both collab and kaggle. However we manage to succeed and obtain a test acc of 0.898 in the end after resizing to 224x224. Not unfreezing the other layers will lead to subpar analysis as our CIFAR-10 dataset is inherently different from ImageNet data. Resizing is also naturally needed to ensure that our data is as close as possible to desired size.\n",
    "###### To further improve our models, it is advised to experiment with adding more dropouts to reduce overfitting or experiment with other more data augmentation methods. Early stopping was already big help in our model, stratified kfold would also help in the case of imbalance classes distributions and add randomization to our fitting process. We also see discussions that learning rate schedulers would also help to improve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603097d",
   "metadata": {},
   "source": [
    "# Appendix:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d414519",
   "metadata": {},
   "source": [
    "## Question 2: Models Experimented\n",
    "##### {'(1.1) MLP with one hidden layer consisting of 128 neurons,adam': 0.48,\n",
    "#####  '(1.2) MLP with one hidden layer consisting of 128 neurons, sgd': 0.51,\n",
    "#####  '(2.1) MLP with one hidden layer consisting of 256 neurons,adam': 0.47,\n",
    "#####  '(2.2) MLP with one hidden layer consisting of 256 neurons,sgd': 0.53,\n",
    "#####  '(3.1) MLP with two hidden layer consisting of 256,128 neurons,relu': 0.48,\n",
    "#####  'Testing 1: MLP with two hidden layer consisting of 256,128 neurons,tanh': 0.36,\n",
    "#####  'Testing 2: MLP with three hidden layer consisting of 256,128,64 neurons,tanh': 0.32,\n",
    "#####  'Testing 3: MLP with three hidden layer consisting of 256,128,64 neurons,LeakyRelu': 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe6d3e2",
   "metadata": {},
   "source": [
    "## Question 3: We tried Pytorch, but it was a headache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f3cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class convNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(convNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1,padding=1)\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2,stride=2)  \n",
    "\n",
    "        self.dropout=nn.Dropout(0.25)\n",
    "        self.fc1=nn.Linear(64*4*4,256)\n",
    "        self.fc2=nn.Linear(256,32)\n",
    "        self.out=nn.Linear(32,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.pool(F.relu(self.conv1(x)))\n",
    "        x=self.pool(F.relu(self.conv2(x)))\n",
    "        x=self.pool(F.relu(self.conv3(x)))\n",
    "        ## print(x.shape)\n",
    "        x = x.view(x.size(0), -1) # Flatten the output of the convolutional layers\n",
    "        x = self.dropout(x)\n",
    "        x=self.dropout(F.relu(self.fc1(x)))\n",
    "        x=self.dropout(F.relu(self.fc2(x)))\n",
    "        x=self.out(x)   \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
